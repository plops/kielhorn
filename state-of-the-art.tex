\newenvironment{fenster}{%
  \begin{addmargin*}[
  5em]{5em}%
    \begin{minipage}{\linewidth}%
    \vspace{1em}
      \rule{\linewidth}{2pt}%
}{%
    \rule[
.25\baselineskip]{\linewidth}{2pt}%
\vspace{1em}
    \end{minipage}%
  \end{addmargin*}%
}
\renewcommand{\H}{\textsf{H}}
\renewcommand{\O}{\textsf{O}}
% /mnt/backup/safe-with-time/torben/safed/y2009/0411
\section{Fundamentals of fluorescence}
\begin{summary}
  Here we give a short overview of the field of fluorescence of
  molecules in order to introduce the terms Stokes shift, triplett
  state and photobleaching.
\end{summary}
First we consider a really simple molecule: We move the nucleii of two
hydrogen atoms and move them slowly together. When the nucleii have a
big distance, the atoms exist as two separate entities without
influence on each other. In the other extreme case the two nucleii are
at the same position and the electrons have the orbitals of a helium
atom.

\begin{figure}[!hbt]
  \centering
  \input{flu-potential_my.eps_tex}
  \caption{Schematic electron density maps and potential curves for
    ground state $\H_2$ and excited state $\H_2^*$ of dihydrogen and
    the dihydrogen ion $\H_2^+$ (after \cite{Haken2006} p.~258).}
  \label{fig:flu-potential_my}
\end{figure}
As a good approximation we can express molecular orbitals as a linear
combination of atomic orbitals and calculate their potential energy in
dependence of the distance between the nucleii (see
\figref{fig:flu-potential_my}). The curve for
$\sigma_g\sigma_g^1\Sigma_g^+$ has minimum at a core distance $R$ of
approximately 1.3 Bohr radii ($a_H=\unit[0.529\cdot10^{-8}]{cm}$). The
compound of two protons and two electrons is particularly stable for
this radius. We call it the hydrogen molecule $\H_2$.

In the same way we can combine a ground state hydrogen atom $\H$ and
an excited hydrogen atom $\H^*$. Again the potential
$\sigma_g\pi_u^1\Pi_u$ has a minimum. That distance of equilibrium is
bigger because the strength of the chemical bond in the excited
hydrogen molecule is decreased.

\begin{figure}[!hbt]
\begin{fenster}
  \minisec{On construction of term symbols}
  {\small
    The
    symmetric linear combination of the $1s$-orbitals of two atoms $A$
    and $B$ is 
    \begin{align*} 
      \sigma_g1s=\frac{1}{\sqrt2}(\sigma 1s_A+\sigma 1s_B).
    \end{align*}
    $\sigma_u$ is constructed as the difference of the two atomic orbitals.
    In general the symmetric molecular orbital $\sigma_g$ is more stable as
    the electrons have a higher probability to be between the nucleii.
    The following quantum numbers describe the molecular wavefunction:
    \begin{description}
    \item[$\Lambda\ ..$] 
      
      Defined by $\mathbf{L}_z=\Lambda\hbar=|\sum\lambda_i|\hbar$ with
      projection $\lambda_i$ of the orbital angular momentum $\mathbf{l}_i$ of
      electron $i$ onto the nuclear axis. $\Lambda$ can take the
      values $0,1,2,\ldots$ and one writes the term symbols
      $\Sigma,\Pi,\Delta,\ldots$.
      
    \item[$S\ ..$]
      
      Spin of all electrons $S=\sum\mathbf{m}_{si}$ in the molecular orbital. 
      
    \item[$\Omega\ ..$] 
      
      Electronic angular momentum in direction of the nuclear axis.
      
    \end{description}
    These numbers are combined into the term symbol like this:
    ${}^{2S+1}\Lambda_\Omega$.  Additionally one writes e.g. $\Sigma^+$
    if the molecular function is symmetric when mirrored at a plane
    through the nucleii.  Furthermore one writes $\Sigma_g$ if the sign
    of wavefunction stays the same when the molecule is inverted at the
    point of symmetry.
    
    Here is an example of the molecular wavefunctions we are
    interested in:
    
    \begin{description}
    \item[$\sigma_g\sigma_g^1\Sigma_g^+$:]
      
      $\lambda_1=1,\ \lambda_2=-1,\ s_1=+,\ s_2=-$
      
      $\Lambda=|\lambda_1+\lambda_2|=|1-1|=0,\ S=s_1+s_2=0$
      
    \item[$\sigma_g\pi_u^1\Pi_u$:]
      
      $\lambda_1=1,\ \lambda_2=-2,\ s_1=+,\ s_2=-$
      
      $\Lambda=|1-2|=1,\ S=0$
      
    \end{description}
  }
\end{fenster}
\end{figure}


\begin{figure}[!hbt]
  \centering
  % (423-120)/423*7 = 4.77 
  \includegraphics[width=6cm,trim=0 0 135 0,clip]{flu-condon}
  \caption{Illustration of the Franck-Condon principle. Potential
    curves for either the same equilibrium core distance in the
    excited state or a bigger core distance in the excited state (from
    \cite{Haken2006} p.~276).}
  \label{fig:flu-condon}
\end{figure}

The distance between the two nucleii is not rigid. The nucleii can
oscillate around their position of equilibrium at quantized
frequencies. These vibration frequencies depend on the strength of the
bond which in turn depends on the excitation state of the
molecule. \figref{fig:flu-condon} shows potential curves for the
ground state and the first excited state of two different
molecules. The left graph shows potential curves of a (theoretical)
molecule where the strength of the bond doesn't change in the excited
state. There, the minima of both curves are exactly on top of each
other. If a ground state molecule absorbs a photon its electron would
be excited but the vibrational state of the core does not change.

The right graph displays the more realistic case of a molecule with a
weaker chemical bond in the excited state. When a photon is absorbed,
the electronic state of the molecule switches essentially
instantaneous compared to the movement of the nucleii. After the
electronic transition the nucleii will start moving because their
equilibrium position changed. In the diagram the absorption event can
be depicted as a vertical line. The same rule applies for emission.

\begin{figure}[!hbt]
  \centering
  \includegraphics[width=9cm]{flu-level_my}
  \caption{A typical energy level diagram. The boxes with up and down
    arrows symbolize the spin of the outer electrons.}
  \label{fig:flu-level}
\end{figure}

It is useful to summarize information about the energy levels of a
molecule in a Jablonski diagram as in \figref{fig:flu-level}. If a
molecule is in the ground state $S_0$ one of its outer electron(s) can
be excited by a photon to either the first excited singlet state $S_1$
or, if the photon has an even higher energy, the electron will go into
the second excited state $S_2$.  The absorption of one photon can not
put the electron into the triplet state $T_1$ as angular momentum must
be conserved.

The electronic absorption event is very rapid (in femtoseconds). Due
to the Franck-Condon principle the electronic excitation also excites
vibrational and rotational modes of the molecule. When the fluorescent
molecule is immersed in a liquid this vibro-rotational excitation will
be transferred to neighbouring molecules in a matter of pico
seconds. This process is called \emph{internal conversion}. The
interaction of the molecule with its surroundings is completely
statistical and the excited electron will loose its phase relationship
with electrons of other fluorescent molecules. A $S_2$ electron will
decay radiationless into $S_1$ due to internal conversion.

A $S_1$ electron can relax into the ground state $S_0$ by emitting a
photon. For this transition the Frank-Condon principle applies
again. A vibro-rotational mode of the ground state will be excited.
Due to internal conversion at two steps during the whole process the
energy of the emitted fluorescence photon is lower than the energy of
the excitation photon (Stokes shift). The fluorescence lifetime -- the
time the molecule stays in state $S_1$ -- is in the range of
nanoseconds.

There is a small probability that the electron doesn't relax and
instead flips its spin (due to spin-orbit coupling\footnote{The
  probability of a spin flip is increased if heavier atoms
  (e.g. bromide) are part of the molecule.}). This process is called
\emph{intersystem crossing}. This mechanism populates the first
triplet state $T_1$. A transition into the ground state $S_0$ would
need another spin-flip of the electron and is quite
improbable. Therefore the triplet state has a long lifetime (several
seconds). The radiative decay is called phosphorescence.
  
The \emph{fluorescence quantum yield} $\eta$ of a fluorophore is
defined as the quotient of the number of emitted (fluorescence)
photons and the number of absorbed photons. In dyes like rhodamine~6G
(in ethanol $\eta=0.94$ \cite{Fischer1996}) or antracene
(9,10-diphenyl anthracene in cyclohexane $\eta=0.90$ \cite{Hamai1983})
its value can be nearly 1 for an appropriate solvent.

\subsection{Photobleaching and phototoxicity}
    
If a fluorophore molecule enters the $T_1$ state it cedes to emit
photons for a long time. The excited molecule could also change its
structure into some non-fluorescent form or react with a
neighbour. All these things result first of all in a decreasing
fluorescence signal -- which is called \emph{photobleaching}.  Another
effect is that the excited fluorophores impair living cells.  It is a
curious quirk of nature that the ground state of the oxygen molecule
is a triplet state ${}^3\O_2$.  If an oxygen molecule hits a $T_1$
fluorophore, e.g.\ ${}^3\textsf{Chlorophyll}^*$, the energy of the dye
can be transferred to the oxygen (\cite{Haken2006} p.438):

\begin{align}
  {}^3\O_2 + {}^3\textsf{Chlorophyll}^* \rightarrow
  {}^1\O^*_2+{}^1\textsf{Chlorophyll}
\end{align}

The resulting singlet oxygen is very reactive and quite hazardous
inside living creatures. Plants have developed several protection
mechanisms, if they are exposed to too much light. Within the cells
they reorient and shift their chloroplasts in order to expose them to
less light. However, they even have a molecular protection mechanism:
They transfer the energy of the chlorophyll onto carotenoid molecules
and can prevent the hazardous \emph{phototoxicity} effects of singlet
oxygen.

Nowadays many methods are known to reduce photobleaching. Supplant
oxygen with noble gases or remove it enzymatically. Depopulate the
triplet state by adding reducing as well as oxidizing agents to the
solvent \citep{Vogelsang2008}. For fixed samples it helps to use
different solvents than water.

All these techniques work after the hazardous chemicals have been
produced. In order to reduce phototoxicity even more it makes sense to
think about the light management in the microscope. 
\section{Conventional microscopes}
\begin{summary}
  Microscopes that are in common use today do not optimally excite
  fluorophores within the specimen. In this section we outline how
  these microscopes work. We explain how out-of-focus blur severely
  limits the performance of the widefield microscope. Then we discuss
  how confocal microscopy improves the sectioning capability at the
  cost of increasing the phototoxic load on the specimen.
\end{summary}
The basic building block of microscopes are lenses. A lens is a piece
of glass with two polished spherical (a shape of lower symmetry is
much harder to manufacture) surfaces. Light is slower in glass than in
air. The shape of a lens redirects photons and the thickness of the
material can delay them. A lens focuses a parallel beam of light into
a spot on its focal plane. The distance between focal plane and the
region where the rays start to converge is called focal length.
\begin{figure}[!hbt]
  \centering
  \input{widefield-microscope.eps_tex}
  \caption{{\bf a)} Schematic of a modern microscope. The sample is in
    the front focal plane of the objective. The detection tubelens TL1
    forms a magnified image on the camera. {\bf b)} Widefield
    epifluorescence excitation. The excitation tubelens focuses a
    laser into the back focal plane (BFP). The beam is reflected by a
    dichroic beam splitter (BS) towards the objective. An extended
    area in the specimen is illuminated. Fluorescence light of lower
    wavelength returns through the objective, is transmitted through
    BS and forms an image on the camera. {\bf c)} Confocal
    microscope. A pinhole PH2 is imaged as a diffraction limited spot
    into the specimen. Returning fluorescence light is only detected
    when it passes through an aligned pinhole PH1. This configuration
    rejects light that doesn't originate from the front focal plane
    (green) of the objective.}
  \label{fig:widefield-microscope}
\end{figure}

The yellow beam in \figref{fig:widefield-microscope}~a) represents
rays that start from the intersection $O$ of the optical axis and the
front focal plane of the objective. The objective collects the rays
and collimates them into a beam that is parallel to the optical
axis. After traversing the tube length $f+f_\textrm{TL}$ the detection
tube lens TL1 focuses the rays on the intersection $O'$ of its focal
plane (the intermediate image plane) and the optical axis.

The blue beam corresponds to rays that start from an off-axis point
$P$ in the front focal plane of the objective. Behind the objective
the blue beam is a parallel beam. However, the beam isn't parallel to
the optical axis. The tube lens TL1 focuses the blue beam into a spot
at $P'$ on its focal plane. Using the theorem of intercepting lines
one obtains for the magnification $M$:
\begin{align}
  M=\frac{\overline{O'P'}}{\overline{OP}}=\frac{f_\textrm{TL}}{f}.
\end{align}
In our microscope we use an objective with magnification $M=63$. The
focal length of the tube lens is \unit[164.5]{mm} for most Zeiss
microscopes. Therefor the focal length of our objective is
$f=\unit[2.61]{mm}$.

Assuming we have a metal mirror with two small
($\diameter<\unit[120]{nm}$) holes in the reflective coating with
$\unit[2]{\mu m}$ distance between them.  We put this object into the
front focal plane of the objective and position a camera on $O'$. When
illuminating the mirror from the side opposite to the objective, the
camera will show two spots with $\unit[126]{\mu m}$ distance.

Note that \figref{fig:widefield-microscope} depicts a thin-lens
model. A real objective contains in the order of ten coated lenses of
different glass and crystalline materials. Their curvatures, positions
and materials were all carefully chosen, taking into account
manufacturing tolerances and wavelengths, so that the microscope
behaves exactly as the thin-lens model predicts. Diffraction defines
how well objective and thin-lens model have to match.\todo[inline]{sine condition!}

It is quite possible that heating to \unit[37]{${}^\circ$C} will ruin
such a high-precision instrument. A related source of aberrations
(departure of design performance) is the refractive index inside of
the specimen. In Appendix~\ref{sec:ray-aberration} we describe a more
complicated model that can predict the effect of embedding the sample
in water (instead of immersion oil with the same refractive index as
the glass).

\subsection{Widefield epifluorescence microscope}
Fluorescence photons are emitted in all directions, independent of the
original illumination direction. Therefor it is convenient to use the
objective for excitation as well as detection. This mode of microscopy
is called epifluorescence (Greek: $\varepsilon\pi\iota$; on, above).
One advantage is that even (the frontal side of) opaque specimen can
be imaged. Furthermore it is beneficial that the illumination needs to
be aligned only once.

\nomenclature{BFP}{Back focal plane}

The red beam in \figref{fig:widefield-microscope}~b) is a parallel
laser. The excitation tube lens TL2 focuses the beam into the back
focal plane (BFP) of the objective. The beam is reflected at a
dichroic beam splitter (BS). This is a glass plate that has been
coated with dielectric layers. The refractive index, thickness and
sequence of the layers are designed so that the excitation light is
reflected towards the objective but lower energy fluorescence light
returning from the objective is transmitted towards the camera. Behind
the objective the beam is parallel and illuminates the specimen.
\subsubsection*{Non-uniformity due to coherent interference}
Note that tiny dirt particles and coherent interference in laser beams
can produce unwanted non-uniformities in the illumination. As a remedy
sometimes the spatial coherence of the laser is reduced. Often
incoherent light emitting diodes, mercury or xenon arc lamps are used
instead of lasers. In the latter case the dichroic beam splitter is
preceded by a band pass filter that selects the useful part of the
lamp's spectrum.

However, independent of the choice of the light source, the widefield
microscope in epifluorescence configuration exposes many layers of the
sample. This leads to fluorescence of out-of-focus fluorophores
(molecules that are not in the front focal plane). The objective
collects their light and forms a blurred image on the camera.
\subsubsection*{Deconvolution}
When a stack of several slices of an object is obtained, it is
possible to suppress the blurred part of each image in all the
others. These algorithms (deconvolution) can improve the perceived
quality of images in some stacks. However, there are two fundamental
problems:

First the ``missing cone problem'' prevents focusing on a homogeneous
fluorescent plane. Physics dictates that there always is a gap in the
transfer function of the objective when the fluorescence process is
linear and the objective collects only photons from one half space.

Second: Even with ideal detectors there is photon shot noise in the
image. In deconvolution algorithms the image of one slice is improved
by subtracting blurred versions of the other slices. When the blurred
intensity is large, its shot noise is high as well. The noise isn't
reduced by subtraction and a faint in-focus image can be severely
deteriorated by the noise of the out-of-focus light.
\subsection{Confocal microscope}
One way of addressing both problems of the widefield microscope is
depicted in \figref{fig:widefield-microscope}~c). In the confocal
microscope the field of view isn't illuminated instantaneously.  The
excitation tube lens TL2 collimates the light coming from a pinhole
PH2 and illuminates the full back focal plane of the objective. In the
front focal plane of the objective the red beam then converges to
illuminate the smallest possible (by diffraction) single
spot. However, out-of-focus fluorophores are still being excited by
the hour-glass shaped illumination.

The eponymous idea of the confocal microscope is to replace the camera
with a pinhole PH1. This pinhole doesn't affect the light detected
from in-focus fluorophores. However, an out-of-focus fluorophore that
is defocused by $\Delta z$ towards the objective will lead to a
diverging beam (green) at the tube lens and will be imaged into a point
behind the focal plane of the tube lens. The pin hole only transmits a
part of the circle of confusion. Hence defocused fluorophores
contribute less to the sensor signal.

An image of the in-focus fluorophores is obtained by scanning the
pinholes over the field of view and measuring intensity at each
position individually. The optical removal of out-of-focus light
prevents degradation of the signal by its shot noise and improves the
point-spread function of the objective (fixing the ``missing cone''
problem). Note however, that some information is lost which would be
obtained in a widefield microscope with deconvolution.

The confocal microscope was invented in 1955 \todo{check patent
  citation} \citep{Minsky1961,Minsky1988} to reduce the influence of
scattering effects in neuron samples stained by Golgi's method. This
invention preceded the laser and was unfortunately not put into
practical use until three decades later \citep{Amos1987}.
\subsection{Phototoxicity in conventional microscopes}
When imaging living specimen we should distinguish between useful and
unnecessary excitation. Taking into account the detection capabilities
of objective lenses we should maximize the ratio of in-focus to
out-of-focus fluorescence. The epifluorescent widefield and confocal
microscope surely do not represent an optimum in this regard.

The following chapter will introduce other microscopy techniques that
are more considerate of where to deposit excitation power within the
specimen.
\subsection{Two photon laser scanning fluorescence microscopy}
If an intense subpicosecond pulse of infrared light is focused into a
spot in the sample, non-linear two photon absorption can occur
\citep{Denk1990}. Infrared light is scattered less than light of half
the wavelength. The phototoxicity in the focus is higher than in a
single-photon microscope with comparable excitation rate. However
there is no excitation in the out-of-focus region. Therefor a
detection pin hole is not required.

This technique has greatly improved depth of penetration and
sensitivity of in situ imaging. %  sentence from otsu 2008
\section{Image detectors in widefield microscopy}
\label{sec:ccd-intro}
\begin{summary}
  Here we describe CCD\nomenclature{CCD}{charge-coupled devices}
  sensors and their characteristics.
\end{summary}
Charge-coupled devices are semiconductor devices that contain a 2D
grid of capacitors, formed by at least three groups of electrodes
(phases). Cycling the voltage on these electrodes allows to push
charges, which has been accumulated under the capacitors (registers)
into their neighbours. They turned out to be the ideal tool to move
charges, produced by photon absorbtion in light sensitive diodes,
across the substrate into read out logic.

Fourty years of development lead to imaging devices with remarkable
charge transfer efficiency, high quantum efficency (up to 95\% with
back illumination) and very low dark currents. Until ten years ago the
performance of CCD imagers in the low light regime was limited by the
noise of the read out amplifier (a few electrons per pixel rms).

Now we have electron multiplying CCD (EM-CCD)
\nomenclature{EM-CCD}{Electron multiplying charge-coupled devices
  (p. \pageref{sec:ccd-intro}, \pageref{sec:ccd-meas})} technology,
which allows comparably good performance at low photon numbers
\citep{Mackay,Robbins2003} and moderate read out speeds (tens of
MHz). EM-CCDs contain a row of additional registers in front of the
read out circuit. There one of the three phases is clocked with a much
higher voltage (up to \unit[40]{V}) then is needed purely for charge
transfer ($\unit[\sim6]{V}$). The large electric fields cause charge
carriers to be accelerated to sufficiently high velocities that
additional carriers are generated by impact ionization. The charge
multiplication per transfer is small ($\sim1\%$) but by using several
hundred registers a substantial gain in the number of charges can be
achieved. In microscopy we usually work with gains of up to
300. Higher gains are possible but limit the dynamic range.

The charge amplification helps to push the read noise from
$\sim\unit[40]{electrons\ rms}$ to significantly below
$\unit[1]{electron\ rms}$ --- in effect creating a sensor limited only
by the photon noise. However the the multiplicative nature of the gain
leads to a perceived reduction in the quantum efficiency of the sensor
(excess noise factor), i.e. an image with
$\unit[100]{photons/pixel}$ without gain will look like the same image
at only $\unit[50]{photons/pixel}$ with EM-gain (see Appendix
\ref{sec:ccd-meas}).


\chapter{Other approaches of light control}
\nomenclature{CLEM}{Controlled light exposure microscopy}%
\begin{summary}
  This chapter gives an overview of current microscopy techniques that
  reduce unnecessary fluorescence excitation and reduce
  phototoxicity. In \emph{light sheet microscopy} an oblique sheet of
  light illuminates the sample without exposing too many out-of-focus
  fluorophores. \emph{Controlled light exposure microscopy}
  (CLEM) takes
  into account the in-focus fluorophore distribution and iteratively
  improves the signal to noise ratio of the measurement.  Finally
  \emph{light field microscopy} allows instantaneous and complete
  control of all parameters of the incoherent light exposure.
\end{summary}
\section{Light sheet fluorescence microscopy}
\begin{summary}
  Light sheets can be directly created with separate optics to
  illuminate the sample from an orthogonal direction. Another
  promising method to create a sheet is to use a high numerical
  aperture objective near the total internal reflection
  angle. Diffraction couples the minimum width of the sheet and the
  extent of the area, where the sheet's with is constant. There is a
  trade-off between sheet width and field of view.
\end{summary}
The idea of illuminating a sample from the side dates back quite
far into the history of microscopy. Already one hundred years ago an
objective perpendicular to the detection objective was used for
illumination of the focal plane in the specimen. This dark field
technique was used to characterize gold nano particles in gold ruby
glass \citep{Siedentopf1903}.

Eventually this technique was applied to fluorescence
microscopy. First to analyze cochlea specimen \citep{Voie1993} and
more recently for the development of embryos
\citep{Huisken2004}. Results in the latter paper have sparked interest
in the technique at many labs \citep{Santi2011}.
\subsection{Light sheet generation with cylindrical lens}
\begin{figure}[!hbt]
  \centering
  %\bild{spim}
  \input{spim-sketch.eps_tex}
  \caption{Schematic of SPIM (selective plane illumination
    microscopy). A cylindrical lens illuminates the specimen with a
    thin sheet of light along the focal plane of the
    objective. Rotating the sample and/or moving it along the axis
    allows to reconstruct a sectioned 3D volume of the fluorophore
    concentration with improved light utilization compared to
    conventional microscopes.}
  \label{fig:spim}
\end{figure}
\figref{fig:spim} shows how the light sheet can be focused into the
specimen using a cylindrical lens. \cite{Huisken2004} employ a water
dipping objective with long working distance (\unit[1\ldots 2]{mm})
and comparatively low NA for detection. A $10\times$ objective with
$\unit[660]{\mu m}$ field of view diameter is used with a sheet that
varies less than $42\%$ in thickness ($\unit[6\ldots 8]{\mu m}$). The
light sheet not only improves sectioning and contrast but also
improves the axial resolution from originally $\unit[14]{\mu m}$ by
nearly a factor of two.

\nomenclature{SPIM}{Selective plane illumination microscopy}

The axial resolution of detection objectives of higher numerical
aperture isn't improved so easily over an extended field of
view. Shading effects, diffraction and refraction can deteriorate the
light sheet. As an improvement of the technique it was suggested to
rotate the specimen or illuminate with multiple sheets of light from
different directions.

Other improvements involve a Bessel beam that is scanned to illuminate
a plane. This intensity distribution is ``self-reconstructing'' and
can compensate better for obstacles in its path. It comes with the
cost that the light sheet isn't as confined. Simultaneous structured
illumination and 2 photon effects were suggested to improve this.


\subsection{Light sheet generation using the detection objective}
\label{sec:hilo}
\begin{figure}[!hbt]
  \centering
  \bild{dunsby}
  \caption{Schematic of oblique plane microscopy (OPM). An index
    matched sample is excited using an oblique plane of light. As the
    illumination plane isn't lying in the focal plane, out-of-focus
    fluorophores on the periphery of the field of view are
    excited. Two additional objectives in the detection path are used
    to reconstruct an aberration free image of all the excited
    fluorophores (drawing from \cite{Dunsby2008}).}
  \label{fig:dunsby}
\end{figure}
Modern high numerical aperture objectives allow to illuminate an
\emph{index matched} sample with a half angle of up to
$70^\circ$. This enables illumination of an oblique and thin sheet of
light in the sample just as in selective plane illumination
microscopy. However this technique (oblique plane microscopy, OPM) has
the advantage, that only one objective is needed to be close to the
sample and it will work with specimen in conventional microscope
slides. One difficulty is that the excited fluorophores are severely
defocused in the intermediate image plane. is that (see
\figref{fig:dunsby}). \cite{Dunsby2008} describe\todo{redraw}\ how to
rotate the observational plane optically in order to recover an
aberration free image from the oblique illumination plane. They
reimage the sample through two additional objectives.

\nomenclature{OPM}{Oblique plane microscopy}

\begin{figure}[!hbt]
  \centering
  \input{hilo-sketch.eps_tex}
  \caption{Schematic of rays in HILO (highly inclined and laminated
    optical sheet) technique. The specimen is embedded in a medium of
    lower optical density than the cover slip. For a very high
    illumination angle (point on the periphery of the back focal
    plane) the light would be reflected at the cover slip-medium
    interface due to total internal reflection. For HILO a point on
    the back focal plane, that is closer to the optic axis is
    illuminated. The light enters the embedding medium in a highly
    inclined angle and only a thin sheet in the focal plane is
    illuminated (after \cite{Tokunaga2008}).}
  \label{fig:hilo}
\end{figure}

Biological specimen are often not index matched but have a lower index
$n_e\approx 1.33$ than the immersion oil $n=1.52$. As indicated in
\figref{fig:hilo} the refraction at the interface between cover slip
glass and embedding medium can be exploited to illuminate specimen
with a light sheet that is nearly parallel to the focal plane.  This
technique is called highly inclined and laminated optical sheet
microscopy (HILO) \citep{Tokunaga2008, Konopka2008}.

\nomenclature{HILO}{Highly inclined and laminated optical sheet microscopy}

Note that the index mismatch between embedding and immersion medium
will introduce aberrations (mostly spherical) which will limit the
imaging depth into the sample.
\section{Scanning techniques for improving light utilization}
\subsection{Controlled light exposure microscopy (CLEM)}
\label{sec:CLEM}
The confocal microscope (see \figref{fig:widefield-microscope}~c)
allows another adaptive illumination technique. A slice of a specimen
is partitioned into three different regions. Areas with no
fluorophores (A), high concentration of fluorophores (C) or a
concentration in between (B).

Ideally, areas A that don't contain fluorophores should only be
exposed until fluorophore content is ruled out. The other two classes
B and C should be exposed until the same number of fluorescence
photons have been detected. This would result in an image with
constant signal to noise ratio. Unfortunately due to the photon nature
of light sometime a region of type B is incorrectly treated as A which
introduces dark pixel artifacts in the image
\citep{Hoebe2010}\todo{read reference}.

In conventional microscopes areas of class C with high fluorophore
concentration are generally exposed too much. Their signal to
noise ratio would be high but this doesn't increase perceived image
quality. Furthermore regions above and below the focal plane have been
unnecessarily subjected to high exposure.


This technique was first presented in \citep{Hoebe2007} \todo{was that
  first, get} followed by an independent similar version with adaptive
control of the laser power for two photon microscopy
\citep{Chu2007}. 

\subsection{Acousto-optic deflectors for fast beam steering}
In a conventional confocal microscope the beam is steered by two
galvanometer mirrors. This technique offers very good light throughput
and is sufficient to obtain rectangular images. However the inertia of
the mirrors severely limit the access rate of spots in the focal
plane.

Replacing the mechanical mirrors with an acoustic wave in a
transparent material (TeO$_2$) enables $\unit[4]{\mu s}$ switching
time \citep{Otsu2008} and even allows focusing to points outside of
the focal plane \citep{Reddy2008}. These acousto-optic deflectors have
lower efficiency (70\% for two AODs) and show chromatic aberrations.

However as descanning isn't necessary in two photon microscopy the
lower efficiency (in the excitation path) is hardly an issue. Therefor
this technique for the first time enables ``random access'' of 3D
coordinates in the sample.

\begin{figure}[!hbt]
  \centering
  \bild{aod} 
  \caption{Schematic of an acousto-optic deflector (AOD) illumination
    system with z focusing. Figure taken from \citep{Reddy2008}}
% in focusing single s highly preferred http://www.future-perfect.co.uk/grammartips/grammar-tip-focussed-focused.asp
  \label{fig:aod}
\end{figure}


\nomenclature{AOD}{Acousto-optic deflector}
\nomenclature{AOM}{Acousto-optic modulator}
\section{Non-scanning}
\subsection{Direct illumination}
An obvious method for doing spatial control is to image a
two-dimensional array of high-power micro-LEDs into the specimen.
\begin{figure}[!hbt]
  \centering
  \includegraphics[width=7cm]{led-array} 
  \caption{Overlay combining widefield micro-LED illumination and
    fluorescence imaging YFP tag expressed in neurons, taken from
    \citep{grossman2010}.}
  \label{fig:led-array}
\end{figure}
However the problem is to achieve sufficient \emph{irradiance} (LEDs
angular emission profile is often lambertian, i.e.\ the back focal
plane of the objective would be over-illuminated and a lot of light
lost) and \emph{fill factor} (it is difficult to put a lot of LEDs
close together). The technique has been demonstrated using a
$64\times64$ array of $\unit[20]{\mu m}$ micro-emitters with
$\unit[50]{\mu m}$ pitch \citep{grossman2010}.  The LEDs can be
switched at millisecond speed and emit at $\unit[(470\pm22)]{nm}$.

\nomenclature{GFP}{Green fluorescent protein}
\nomenclature{EGFP}{Enhanced green fluorescent protein}
\nomenclature{YFP}{Yellow fluorescent protein}
\nomenclature{VCSEL}{Vertical-cavity surface-emitting laser}
\nomenclature{LED}{Light-emitting diode}
\nomenclature{MMA}{micro-mirror array}
\nomenclature{LCoS}{Liquid crystal on silcon (display)}
\nomenclature{DPSS}{Diode-pumped solid-state (laser)}

This technique enables interesting experiments where processes are
influenced by light (optogenetics) but the targets ideally have to be
located in the focal plane. Also it must be verified that the
illumination cone of each LED image doesn't affect the measurement,
i.e.\ activate the specimen in out-of-focus regions.

Nevertheless once the LED (or VCSEL) arrays become available in
interesting spectral ranges we might see the direct illumination
techniques more often.

\subsection{Intensity modulation}
\subsubsection{Programmable array microscopy}
A technique similar to controlled light exposure microscopy (CLEM,
section \ref{sec:CLEM}) has been implemented in a programmable array
microscope (PAM) \citep{Caarls2011} (minimized light exposure PAM,
MLE-PAM). Like our microscope the PAM images a pattern into the sample
using a spatial light modulator. In addition to our system the same
SLM is used in the detection path to recover an image of only the
in-focus fluorophores.

\begin{figure}[!hbt]
  \centering
  \input{pam-sketch.eps_tex}
  \caption{Schematic of a programmable array microscope (PAM) (after
    \cite{Verveer1998}). A digital micromirror device (DMD) containing
    an array of tiltable mirrors is imaged into the focal plane of the
    objective. Returning fluorescent light from out-of-focus
    fluorophores is distributed onto both cameras. In-focus
    fluorescence is only imaged onto camera 1.}
  \label{fig:pam-sketch}
\end{figure}


\nomenclature{PAM}{Programmable array microscopy}%
\nomenclature{DMD}{Digital micromirror device}%
\nomenclature{MLE-PAM}{Minimized light exposure programmable array microscope}%

\subsubsection{Light field microscopy}
Interesting work on light fields originally started in the macroscopic
domain of cameras \citep{Lippmann1908%,Sokolov1911
} and was eventually
applied as a technique for microscopy
\citep{Levoy2006,Levoy2009,Zhang2009}. This approach is built on imaging through
an array of microlenses.
\begin{figure}[!hbt]
  \centering
  %\includegraphics[width=7cm]{microlens-levoy-sketch} %FIXME redraw
  \input{microlens-levoy-sketch.eps_tex}
  \caption{Schematic of microlenses in intermediate image plane (after
    \citep{Levoy2006})}
  \label{fig:microlens-levoy-sketch}
\end{figure}

A microlens array is placed behind the intermediate image plane (see
\figref{fig:microlens-levoy-sketch}). The light that illuminates one
microlens corresponds to one spot in the focal plane of the
sample. The camera is positioned in the focal plane of the microlenses
and captures an image of the back focal plane behind each microlens
(see dashed ray bundle).

The camera captures the four dimensional light field leaving the
specimen with spatial coordinates $(s,t)$ and angular coordinates
$(u,v)$. This data enables computational viewpoint shifting,
refocusing, extended depth of field and aberration correction of the
detected fluorescence emission.


\begin{figure}[!hbt]
  \centering
  \input{microlens-levoy-sketch_2.eps_tex}
  \caption{Construction of an out-of-focus bundle through the light
    field microscope. In order to improve the readability of the
    drawing, the magnification in the microscope was set to $1:1$
    (focal lengths of tube lens and objective are equal). An on-axis
    sample point originating from below the focal plane of the
    objective is imaged into an on axis point between tubelens and
    microlens array. Three of the microlenses reimage the point into
    three points behind the plane of the camera.}
  \label{fig:microlens-levoy-sketch_2}
\end{figure}

\figref{fig:microlens-levoy-sketch_2} shows bundles originating from
an out-of-focus point. Each of the microlenses that are hit by the
circle of confusion reimage a fraction of the of the angular range of
into their images.  This process is crucial because here a lot of the
original image information is lost. The intensities from the
sub-images on the camera can't later be recombined in order to,
e.g. recover a high resolution image of the defocused point
(R.~Heintzmann, personal communication, November 22, 2011).

The light field microscope doesn't utilize the full resolution of
high-NA objectives. This will prevent the use of this technique in its
current form for the detection path of microscopes.

However, the same ideas can be applied in the excitation path. For
illumination purposes lower resolution will often suffice. The light
field technique allows unique control of excitation light intensity
and angles in each point of the sample plane.

\subsection{Temporal focusing}
\begin{figure}[!hbt]
  \centering
  %\bild{oron} 
  \input{temporal-focus-sketch.eps_tex}
  \caption{Schematic of temporal focusing (after \citep{Oron2005}). A
    grating in the intermediate image plane separates the pulse into
    its spectral components. Out-of-focus areas of the specimen are
    illuminated with a longer pulse. Only the in the focal plane all
    spectral components interfere coherently and form a short
    intensive pulse.}
  \label{fig:oron}
\end{figure}
The axial extent of ultra-short laser pulses can be as thin as a few
microns. A parallel beam can be split into different spectral
components by a grating in the intermediate image plane
\citep{Oron2005}. The tube lens focuses the diffraction pattern into a
line in the back focal plane of the objective.

The objective, which has to be corrected for chromatic aberration and
dispersion, then focuses all the beams into the focal plane. Different
spectral components arrive in the focal plane at the same
time. Out-of-focus points see an extended illumination. For a high NA
objective a pulse duration of $\tau=\unit[20]{fs}$ results in slice of
$z\approx\tau c/2\approx\unit[3]{\mu m}$ thickness around the focus,
where the beam has significant intensity.

Using this technique it is possible to build a widefield two photon
microscope. That only excites fluorophores within the focal plane. The
technique can be further improved by spatially modulating the beam
in the intermediate image plane for CLEM like performance.

\subsection{Phase modulation}
\subsubsection{Digital holography}
\begin{figure}[!hbt]
  \centering
  \includegraphics[height=5cm]{phase-holo} 
  \caption{Schematic of spatial illumination by phase holography
    \todo[inline]{redraw}}
  \label{fig:phase-holo}
\end{figure}
Certain types of liquid crystal spatial light modulators can be used
to modify the phase of light. When such a device is placed into the
back focal plane of a lens, it is possible to control the light
distribution in its front focal plane. An iterative algorithm
(iterative Fourier transform algorithm, IFTA) can be used to establish
a phase image on the liquid crystal display that will result in an
intensity distribution in front of the lens.

\nomenclature{IFTA}{Iterative Fourier transform algorithm}

This approach has been used to excite a two-dimensional pattern in the
specimen \citep{Lutz2008,Zahid2010} and is advantageous especially for
cases where only small parts of the specimen ought to be
illuminated. As opposed to conventional intensity spatial light
modulators the light can be redirected from dark areas into the bright
areas.

% single photon 405nm uncaging, ifta,
% spherical wave approximation
There is also a limited possibility to create three-dimensional
patterns, e.g.\ several points below, in and above the focal plane by
displaying Fresnel zone planes.  For illumination usually a laser with
non-zero interference length is employed. However, this illumination
contains an unwanted ``speckle'' pattern -- noisy non-uniformities. To
a certain extent the contrast of the speckle pattern can be reduced by
controlling spatial and temporal coherence of the illumination
(sweeping the frequency of the laser or changing illumination
direction while the detector is integrating).

Holographic control can be used with two photon excitation as well
\citep{Nikolenko2008} % two photon
but this exacerbates the effect of speckles.
\subsubsection{Generalised phase contrast (GPC)}
\begin{figure}[!hbt]
  \centering
  \includegraphics[width=14cm]{phase} % FIXME redraw
  \caption{schematic of generalized phase contrast \citep{Rodrigo2008}}
  \label{fig:phase}
\end{figure}
A phase contrast microscope objective \todo{modified ?} can be used to
convert a phase image from the intermediate image plane into an
intensity image in the specimen \citep{Rodrigo2008}\todo{read more of
  this}. Compared to digital holography hardly any computation is
necessary. Yet the phase spatial light modulator allows concentrating
a lot of light even into a small region of the specimen as opposed to
other techniques which involve intensity modulation and loose the
light of dark areas.

The generalised phase contrast method is suitable even with spatially
incoherent illumination\todo{slightly ?}.
\subsubsection{Generalised phase contrast and temporal focusing (TF-GPC)}
The combination of generalised phase contrast and temporal focusing
allows selective uniform illumination of in-focus areas
\citep{Papagiakoumou2010}. Usage of a phase spatial light modulator
results in high light efficiency compared to intensity modulation.
Splitting and recombination of the spectral components of the pulse
reduce speckle noise considerably.
\begin{figure}[!hbt]
  \centering
  \includegraphics[width=11cm]{tf-gpc} 
  \caption{Schematic of phase contrast with temporal focusing (TF-GPC)
    from \citep{Papagiakoumou2010}, PCF is a phase contrast filter}
  \label{fig:tf-gpc}
\end{figure}
\nomenclature{PCF}{Phase contrast filter}
